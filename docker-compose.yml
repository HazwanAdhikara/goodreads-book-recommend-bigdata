services:
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - goodreads-network

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    networks:
      - goodreads-network

  # MinIO (S3-compatible storage)
  minio:
    image: minio/minio:latest
    hostname: minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - goodreads-network

  minio-client:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set myminio http://minio:9000 minioadmin minioadmin &&
      mc mb myminio/streaming-data || echo 'Bucket already exists';
      mc mb myminio/models || echo 'Models bucket already exists';
      exit 0;"
    networks:
      - goodreads-network

  # Apache Spark Master
  spark-master:
    image: bitnami/spark:latest
    platform: linux/amd64 # Force AMD64 for Apple Silicon compatibility
    hostname: spark-master
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      # S3 Configuration for MinIO
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    ports:
      - "8082:8082" # Spark Master Web UI
      - "7077:7077" # Spark Master Port
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./data:/opt/spark-data
    depends_on:
      - minio
    networks:
      - goodreads-network

  # Apache Spark Worker
  spark-worker:
    image: bitnami/spark:latest
    platform: linux/amd64 # Force AMD64 for Apple Silicon compatibility
    hostname: spark-worker
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      # S3 Configuration for MinIO
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    depends_on:
      - spark-master
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks:
      - goodreads-network

  # Streamlit Dashboard
  streamlit-dashboard:
    build:
      context: ./streamlit-app
      dockerfile: Dockerfile
    hostname: streamlit-dashboard
    container_name: streamlit-dashboard
    ports:
      - "8501:8501"
    volumes:
      - ./streamlit-app:/app
      - ./data:/app/data
    depends_on:
      - kafka
      - minio
    networks:
      - goodreads-network

volumes:
  minio-data:
    driver: local

networks:
  goodreads-network:
    driver: bridge
